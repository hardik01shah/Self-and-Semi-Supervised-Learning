{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrishi508/Self-and-Semi-Supervised-Learning/blob/main/Supervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofe8YH8BOEN"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyagcRRwMeo5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMyDn3HSLhq9",
        "outputId": "68496340-6ca1-488a-aa13-d18274671986"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "ZyzT-NmPUWig",
        "outputId": "fe7ede62-73a2-4747-a4a1-d449ae926f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty1XcIxvBShg"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYLWrg3vOr87"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15)\n",
        "])\n",
        "\n",
        "training_data = datasets.STL10(\n",
        "    root=\"data\",\n",
        "    split=\"train\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "\n",
        "test_data = datasets.STL10(\n",
        "    root=\"data\",\n",
        "    split='test',\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSBxBfF4TPpc"
      },
      "source": [
        "## HYPERPARAMETERS\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.001\n",
        "EPOCHS = 100\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMsoyhwD-t5q"
      },
      "source": [
        "def imshow(img):\n",
        "    t1 = torch.tensor([0.485, 0.456, 0.406])\n",
        "    t2 = torch.tensor([0.229, 0.224, 0.225])\n",
        "    img[0]*=t2[0]\n",
        "    img[1]*=t2[1]\n",
        "    img[2]*=t2[2]\n",
        "\n",
        "    img[0]+=t1[0]\n",
        "    img[1]+=t1[1]\n",
        "    img[2]+=t1[2]\n",
        "\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs0BekaJRcdT"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"airplane\",\n",
        "    1: \"bird\",\n",
        "    2: \"car\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"horse\",\n",
        "    7: \"monkey\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\",\n",
        "}\n",
        "img, label = training_data[155]\n",
        "imshow(img)\n",
        "print(labels_map[label])\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFrlZqG3UgIv"
      },
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "img = train_features[0]\n",
        "imshow(img)\n",
        "print(labels_map[train_labels[0].item()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oQIBiBhMaGm"
      },
      "source": [
        "## Train and Test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-ROd9ydAsg_"
      },
      "source": [
        "def train_model(model, dataloader, loss_func, optimizer, num_epochs = EPOCHS):\n",
        "    since = time.time()\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)        \n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):                    \n",
        "                outputs = model(inputs)\n",
        "                outputs = outputs.to(device)\n",
        "                loss = loss_func(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model):\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "\n",
        "  for X,y in test_dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      y_pred = model(X)\n",
        "      _, predicted = torch.max(y_pred.data, 1)\n",
        "      total += y.size(0)\n",
        "      corrects += (predicted == y).sum().item()\n",
        "\n",
        "  print(f\"Accuracy of the model : {(float(corrects)/total)*100}%\")"
      ],
      "metadata": {
        "id": "8jbB93OmYx4c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet 9 Model"
      ],
      "metadata": {
        "id": "0KZPAtqxKxDl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C1oz5ASdxD0"
      },
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "                nn.BatchNorm2d(out_channels), \n",
        "                nn.ReLU(inplace=True)\n",
        "              ]\n",
        "\n",
        "    if pool: \n",
        "      layers.append(nn.MaxPool2d(2))\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(ResNet9, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64,pool=True)\n",
        "        self.conv2 = conv_block(64, 128, pool=True) \n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), \n",
        "                                  conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), \n",
        "                                  conv_block(512, 512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(6), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gLPsi9dhkJ",
        "outputId": "1bab94cd-2646-4fc5-adae-100bfd30b980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = ResNet9(3, 10)\n",
        "print(model)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debug Block"
      ],
      "metadata": {
        "id": "t69bYjvnYIG1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDWWLkYuKhia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37878a58-6fcf-4538-c3dc-477f329f832d"
      },
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv_layer = nn.Sequential(\n",
        "\n",
        "#             # Conv Layer block 1\n",
        "#             nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=0),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=0),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "#             # Conv Layer block 2\n",
        "#             nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=0),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=128, out_channels=128, kernel_size=5, padding=0),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#             nn.Dropout2d(p=0.06),\n",
        "\n",
        "#             # Conv Layer block 3\n",
        "#             nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=0),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=0),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#         )\n",
        "\n",
        "\n",
        "#         self.fc_layer = nn.Sequential(\n",
        "#             nn.Dropout(p=0.15),\n",
        "#             nn.Linear(6400, 1024),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Linear(1024, 512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout(p=0.15),\n",
        "#             nn.Linear(512, 10),\n",
        "#         )\n",
        "\n",
        "\n",
        "#     def forward(self, x):        \n",
        "#         # conv layers\n",
        "#         x = self.conv_layer(x)\n",
        "        \n",
        "#         # flatten\n",
        "#         x = x.view(x.size(0), -1)\n",
        "        \n",
        "#         # fc layer\n",
        "#         x = self.fc_layer(x)\n",
        "\n",
        "#         return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "HEQrS6HbYNZ_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxlu82mXtl0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51763f29-db5a-4aa9-d09b-936a9cc941f9"
      },
      "source": [
        "train_model(model, train_dataloader, loss_fn, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 2.0659 Acc: 0.2930\n",
            "val Loss: 1.6522 Acc: 0.3925\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 1.7347 Acc: 0.3564\n",
            "val Loss: 1.9217 Acc: 0.3384\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 1.5737 Acc: 0.4256\n",
            "val Loss: 1.5449 Acc: 0.4330\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 1.4200 Acc: 0.4728\n",
            "val Loss: 1.4033 Acc: 0.4744\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 1.3149 Acc: 0.5086\n",
            "val Loss: 1.3601 Acc: 0.5016\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 1.2712 Acc: 0.5394\n",
            "val Loss: 1.3663 Acc: 0.5024\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 1.2123 Acc: 0.5566\n",
            "val Loss: 1.4033 Acc: 0.5079\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 1.1505 Acc: 0.5752\n",
            "val Loss: 1.3920 Acc: 0.5242\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 1.0839 Acc: 0.6042\n",
            "val Loss: 1.4143 Acc: 0.5058\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 1.0232 Acc: 0.6250\n",
            "val Loss: 1.1762 Acc: 0.5820\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 1.0127 Acc: 0.6280\n",
            "val Loss: 1.5946 Acc: 0.4725\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.9952 Acc: 0.6364\n",
            "val Loss: 1.6431 Acc: 0.4785\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.9779 Acc: 0.6422\n",
            "val Loss: 1.4868 Acc: 0.4806\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.9207 Acc: 0.6648\n",
            "val Loss: 1.4081 Acc: 0.5517\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.9317 Acc: 0.6650\n",
            "val Loss: 1.0858 Acc: 0.6278\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.8916 Acc: 0.6798\n",
            "val Loss: 1.0333 Acc: 0.6324\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.8213 Acc: 0.7020\n",
            "val Loss: 1.3539 Acc: 0.5686\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.8033 Acc: 0.7094\n",
            "val Loss: 1.1771 Acc: 0.6119\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.8550 Acc: 0.6884\n",
            "val Loss: 1.3627 Acc: 0.5654\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.7817 Acc: 0.7156\n",
            "val Loss: 1.0109 Acc: 0.6560\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.7525 Acc: 0.7258\n",
            "val Loss: 0.9252 Acc: 0.6819\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.7280 Acc: 0.7320\n",
            "val Loss: 0.9356 Acc: 0.6714\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.7476 Acc: 0.7330\n",
            "val Loss: 1.1143 Acc: 0.6306\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.7080 Acc: 0.7430\n",
            "val Loss: 1.0840 Acc: 0.6361\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.6618 Acc: 0.7640\n",
            "val Loss: 1.3525 Acc: 0.5879\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.6342 Acc: 0.7708\n",
            "val Loss: 1.2849 Acc: 0.5861\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.6160 Acc: 0.7732\n",
            "val Loss: 1.0705 Acc: 0.6460\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.6516 Acc: 0.7648\n",
            "val Loss: 0.9677 Acc: 0.6666\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.6074 Acc: 0.7814\n",
            "val Loss: 1.0745 Acc: 0.6459\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.5894 Acc: 0.7834\n",
            "val Loss: 0.8441 Acc: 0.7179\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.5768 Acc: 0.7944\n",
            "val Loss: 0.9002 Acc: 0.6914\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.5477 Acc: 0.8010\n",
            "val Loss: 0.8133 Acc: 0.7258\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.5381 Acc: 0.8048\n",
            "val Loss: 1.0786 Acc: 0.6700\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.5525 Acc: 0.7990\n",
            "val Loss: 1.0441 Acc: 0.6759\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.5164 Acc: 0.8132\n",
            "val Loss: 0.8213 Acc: 0.7228\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.5256 Acc: 0.8136\n",
            "val Loss: 0.8843 Acc: 0.7070\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.4653 Acc: 0.8346\n",
            "val Loss: 0.8090 Acc: 0.7340\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.4858 Acc: 0.8308\n",
            "val Loss: 0.9966 Acc: 0.6883\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.4942 Acc: 0.8270\n",
            "val Loss: 1.0349 Acc: 0.6684\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.4130 Acc: 0.8484\n",
            "val Loss: 1.0833 Acc: 0.6850\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.4318 Acc: 0.8478\n",
            "val Loss: 1.2080 Acc: 0.6576\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.5087 Acc: 0.8252\n",
            "val Loss: 0.8180 Acc: 0.7381\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.4006 Acc: 0.8532\n",
            "val Loss: 0.8920 Acc: 0.7209\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.4233 Acc: 0.8528\n",
            "val Loss: 0.9509 Acc: 0.7009\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.3714 Acc: 0.8678\n",
            "val Loss: 0.8951 Acc: 0.7290\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.3622 Acc: 0.8678\n",
            "val Loss: 1.0988 Acc: 0.6930\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.3463 Acc: 0.8740\n",
            "val Loss: 0.8965 Acc: 0.7230\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.3844 Acc: 0.8658\n",
            "val Loss: 1.1254 Acc: 0.6736\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.3174 Acc: 0.8820\n",
            "val Loss: 0.8790 Acc: 0.7348\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.3195 Acc: 0.8844\n",
            "val Loss: 1.0424 Acc: 0.7016\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n",
            "train Loss: 0.3377 Acc: 0.8804\n",
            "val Loss: 0.8393 Acc: 0.7456\n",
            "\n",
            "Epoch 51/99\n",
            "----------\n",
            "train Loss: 0.3259 Acc: 0.8816\n",
            "val Loss: 1.0474 Acc: 0.7074\n",
            "\n",
            "Epoch 52/99\n",
            "----------\n",
            "train Loss: 0.2849 Acc: 0.8942\n",
            "val Loss: 0.9749 Acc: 0.7198\n",
            "\n",
            "Epoch 53/99\n",
            "----------\n",
            "train Loss: 0.3118 Acc: 0.8834\n",
            "val Loss: 1.1716 Acc: 0.6761\n",
            "\n",
            "Epoch 54/99\n",
            "----------\n",
            "train Loss: 0.3293 Acc: 0.8818\n",
            "val Loss: 0.9788 Acc: 0.7176\n",
            "\n",
            "Epoch 55/99\n",
            "----------\n",
            "train Loss: 0.2568 Acc: 0.9096\n",
            "val Loss: 1.0182 Acc: 0.7179\n",
            "\n",
            "Epoch 56/99\n",
            "----------\n",
            "train Loss: 0.2497 Acc: 0.9102\n",
            "val Loss: 0.9716 Acc: 0.7275\n",
            "\n",
            "Epoch 57/99\n",
            "----------\n",
            "train Loss: 0.2504 Acc: 0.9130\n",
            "val Loss: 0.9731 Acc: 0.7241\n",
            "\n",
            "Epoch 58/99\n",
            "----------\n",
            "train Loss: 0.2042 Acc: 0.9288\n",
            "val Loss: 0.9512 Acc: 0.7344\n",
            "\n",
            "Epoch 59/99\n",
            "----------\n",
            "train Loss: 0.2049 Acc: 0.9232\n",
            "val Loss: 1.0522 Acc: 0.7174\n",
            "\n",
            "Epoch 60/99\n",
            "----------\n",
            "train Loss: 0.2645 Acc: 0.9070\n",
            "val Loss: 1.3015 Acc: 0.6601\n",
            "\n",
            "Epoch 61/99\n",
            "----------\n",
            "train Loss: 0.2409 Acc: 0.9138\n",
            "val Loss: 1.1402 Acc: 0.7176\n",
            "\n",
            "Epoch 62/99\n",
            "----------\n",
            "train Loss: 0.2310 Acc: 0.9186\n",
            "val Loss: 0.9600 Acc: 0.7408\n",
            "\n",
            "Epoch 63/99\n",
            "----------\n",
            "train Loss: 0.2646 Acc: 0.9002\n",
            "val Loss: 0.9730 Acc: 0.7335\n",
            "\n",
            "Epoch 64/99\n",
            "----------\n",
            "train Loss: 0.2302 Acc: 0.9146\n",
            "val Loss: 1.1361 Acc: 0.7033\n",
            "\n",
            "Epoch 65/99\n",
            "----------\n",
            "train Loss: 0.2473 Acc: 0.9144\n",
            "val Loss: 0.9487 Acc: 0.7364\n",
            "\n",
            "Epoch 66/99\n",
            "----------\n",
            "train Loss: 0.2253 Acc: 0.9202\n",
            "val Loss: 1.0192 Acc: 0.7324\n",
            "\n",
            "Epoch 67/99\n",
            "----------\n",
            "train Loss: 0.2311 Acc: 0.9172\n",
            "val Loss: 0.8874 Acc: 0.7519\n",
            "\n",
            "Epoch 68/99\n",
            "----------\n",
            "train Loss: 0.1932 Acc: 0.9348\n",
            "val Loss: 1.0099 Acc: 0.7309\n",
            "\n",
            "Epoch 69/99\n",
            "----------\n",
            "train Loss: 0.2265 Acc: 0.9176\n",
            "val Loss: 0.9185 Acc: 0.7508\n",
            "\n",
            "Epoch 70/99\n",
            "----------\n",
            "train Loss: 0.1697 Acc: 0.9392\n",
            "val Loss: 0.9805 Acc: 0.7395\n",
            "\n",
            "Epoch 71/99\n",
            "----------\n",
            "train Loss: 0.2307 Acc: 0.9160\n",
            "val Loss: 0.9836 Acc: 0.7426\n",
            "\n",
            "Epoch 72/99\n",
            "----------\n",
            "train Loss: 0.1584 Acc: 0.9420\n",
            "val Loss: 0.9655 Acc: 0.7558\n",
            "\n",
            "Epoch 73/99\n",
            "----------\n",
            "train Loss: 0.1603 Acc: 0.9428\n",
            "val Loss: 1.0835 Acc: 0.7321\n",
            "\n",
            "Epoch 74/99\n",
            "----------\n",
            "train Loss: 0.1707 Acc: 0.9374\n",
            "val Loss: 0.9019 Acc: 0.7554\n",
            "\n",
            "Epoch 75/99\n",
            "----------\n",
            "train Loss: 0.1574 Acc: 0.9448\n",
            "val Loss: 1.0319 Acc: 0.7461\n",
            "\n",
            "Epoch 76/99\n",
            "----------\n",
            "train Loss: 0.1463 Acc: 0.9484\n",
            "val Loss: 0.9934 Acc: 0.7414\n",
            "\n",
            "Epoch 77/99\n",
            "----------\n",
            "train Loss: 0.1098 Acc: 0.9606\n",
            "val Loss: 0.9529 Acc: 0.7636\n",
            "\n",
            "Epoch 78/99\n",
            "----------\n",
            "train Loss: 0.1277 Acc: 0.9570\n",
            "val Loss: 1.0501 Acc: 0.7404\n",
            "\n",
            "Epoch 79/99\n",
            "----------\n",
            "train Loss: 0.1179 Acc: 0.9614\n",
            "val Loss: 1.0312 Acc: 0.7486\n",
            "\n",
            "Epoch 80/99\n",
            "----------\n",
            "train Loss: 0.1369 Acc: 0.9508\n",
            "val Loss: 1.0994 Acc: 0.7465\n",
            "\n",
            "Epoch 81/99\n",
            "----------\n",
            "train Loss: 0.1783 Acc: 0.9390\n",
            "val Loss: 1.0514 Acc: 0.7331\n",
            "\n",
            "Epoch 82/99\n",
            "----------\n",
            "train Loss: 0.1544 Acc: 0.9486\n",
            "val Loss: 1.1179 Acc: 0.7466\n",
            "\n",
            "Epoch 83/99\n",
            "----------\n",
            "train Loss: 0.1830 Acc: 0.9400\n",
            "val Loss: 1.2513 Acc: 0.7117\n",
            "\n",
            "Epoch 84/99\n",
            "----------\n",
            "train Loss: 0.1238 Acc: 0.9566\n",
            "val Loss: 1.0299 Acc: 0.7435\n",
            "\n",
            "Epoch 85/99\n",
            "----------\n",
            "train Loss: 0.1087 Acc: 0.9610\n",
            "val Loss: 1.0273 Acc: 0.7540\n",
            "\n",
            "Epoch 86/99\n",
            "----------\n",
            "train Loss: 0.1616 Acc: 0.9436\n",
            "val Loss: 1.2405 Acc: 0.7176\n",
            "\n",
            "Epoch 87/99\n",
            "----------\n",
            "train Loss: 0.1792 Acc: 0.9408\n",
            "val Loss: 1.0951 Acc: 0.7436\n",
            "\n",
            "Epoch 88/99\n",
            "----------\n",
            "train Loss: 0.0975 Acc: 0.9674\n",
            "val Loss: 0.8894 Acc: 0.7678\n",
            "\n",
            "Epoch 89/99\n",
            "----------\n",
            "train Loss: 0.1127 Acc: 0.9628\n",
            "val Loss: 1.1431 Acc: 0.7400\n",
            "\n",
            "Epoch 90/99\n",
            "----------\n",
            "train Loss: 0.2019 Acc: 0.9356\n",
            "val Loss: 1.0365 Acc: 0.7484\n",
            "\n",
            "Epoch 91/99\n",
            "----------\n",
            "train Loss: 0.1013 Acc: 0.9632\n",
            "val Loss: 0.9688 Acc: 0.7659\n",
            "\n",
            "Epoch 92/99\n",
            "----------\n",
            "train Loss: 0.1007 Acc: 0.9636\n",
            "val Loss: 1.1186 Acc: 0.7405\n",
            "\n",
            "Epoch 93/99\n",
            "----------\n",
            "train Loss: 0.0780 Acc: 0.9752\n",
            "val Loss: 1.2071 Acc: 0.7320\n",
            "\n",
            "Epoch 94/99\n",
            "----------\n",
            "train Loss: 0.1077 Acc: 0.9608\n",
            "val Loss: 1.0515 Acc: 0.7611\n",
            "\n",
            "Epoch 95/99\n",
            "----------\n",
            "train Loss: 0.1142 Acc: 0.9616\n",
            "val Loss: 1.0294 Acc: 0.7570\n",
            "\n",
            "Epoch 96/99\n",
            "----------\n",
            "train Loss: 0.1285 Acc: 0.9534\n",
            "val Loss: 1.0075 Acc: 0.7652\n",
            "\n",
            "Epoch 97/99\n",
            "----------\n",
            "train Loss: 0.0942 Acc: 0.9688\n",
            "val Loss: 1.3115 Acc: 0.7190\n",
            "\n",
            "Epoch 98/99\n",
            "----------\n",
            "train Loss: 0.0815 Acc: 0.9714\n",
            "val Loss: 1.1158 Acc: 0.7530\n",
            "\n",
            "Epoch 99/99\n",
            "----------\n",
            "train Loss: 0.0807 Acc: 0.9690\n",
            "val Loss: 1.1081 Acc: 0.7532\n",
            "\n",
            "Training complete in 69m 12s\n",
            "Best val Acc: 0.767750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ResNet9(\n",
              "   (conv1): Sequential(\n",
              "     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (2): ReLU(inplace=True)\n",
              "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "   )\n",
              "   (conv2): Sequential(\n",
              "     (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (2): ReLU(inplace=True)\n",
              "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "   )\n",
              "   (res1): Sequential(\n",
              "     (0): Sequential(\n",
              "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): ReLU(inplace=True)\n",
              "     )\n",
              "     (1): Sequential(\n",
              "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): ReLU(inplace=True)\n",
              "     )\n",
              "   )\n",
              "   (conv3): Sequential(\n",
              "     (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (2): ReLU(inplace=True)\n",
              "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "   )\n",
              "   (conv4): Sequential(\n",
              "     (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (2): ReLU(inplace=True)\n",
              "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "   )\n",
              "   (res2): Sequential(\n",
              "     (0): Sequential(\n",
              "       (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): ReLU(inplace=True)\n",
              "     )\n",
              "     (1): Sequential(\n",
              "       (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): ReLU(inplace=True)\n",
              "     )\n",
              "   )\n",
              "   (classifier): Sequential(\n",
              "     (0): MaxPool2d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
              "     (1): Flatten(start_dim=1, end_dim=-1)\n",
              "     (2): Dropout(p=0.2, inplace=False)\n",
              "     (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "   )\n",
              " ),\n",
              " [tensor(0.3925, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.3384, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.4330, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.4744, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5016, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5024, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5079, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5242, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5058, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5820, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.4725, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.4785, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.4806, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5517, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6278, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6324, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5686, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6119, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5654, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6560, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6819, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6714, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6306, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6361, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5879, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.5861, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6460, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6666, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6459, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7179, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6914, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7258, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6700, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6759, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7228, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7070, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7340, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6883, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6684, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6850, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6576, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7381, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7209, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7009, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7290, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6930, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7230, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6736, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7348, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7016, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7456, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7074, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7198, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6761, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7176, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7179, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7275, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7241, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7344, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7174, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6601, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7176, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7408, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7335, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7033, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7364, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7324, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7519, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7309, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7508, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7395, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7426, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7558, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7321, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7554, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7461, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7414, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7636, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7404, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7486, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7465, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7331, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7466, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7117, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7435, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7540, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7176, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7436, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7678, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7400, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7484, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7659, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7405, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7320, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7611, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7570, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7652, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7190, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7530, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7532, device='cuda:0', dtype=torch.float64)])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/data/weights_stl10.pth\", map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "iG5HvHdgfcQc",
        "outputId": "894356ae-5dcd-4135-c5e2-dd62c29090ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model)"
      ],
      "metadata": {
        "id": "spMRhhUiY9ou",
        "outputId": "e3b5f0bd-3349-4f4a-e144-e83cf54ed510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model : 74.875%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWe0l277Uv68"
      },
      "source": [
        "# torch.save(model_ft.state_dict(), '/content/drive/MyDrive/data/weights_stl10.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}